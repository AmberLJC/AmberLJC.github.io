<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Unlocking Capabilities Beyond Pre-training: Fine-Tuning and Other Techniques</title>
<script src="https://cdn.tailwindcss.com"></script>
<style>
    :root {
        --primary-color: #37352f;
        --border-color: #e1e5e9;
        --background-color: #ffffff;
        --hover-bg: #f7f6f3;
    }
    body {
        margin-top: 80px;
        background-color: var(--background-color);
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        line-height: 1.7;
        color: #374151;
    }
    .topnav {
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        background-color: rgba(255, 255, 255, 0.98);
        backdrop-filter: blur(12px);
        border-bottom: 1px solid #e5e7eb;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        overflow: hidden;
        z-index: 1000;
        display: flex;
        align-items: center;
        height: 60px;
        padding: 0 24px;
        margin: 0;
    }
    .topnav a {
        display: block;
        color: #374151;
        text-align: center;
        padding: 8px 16px;
        text-decoration: none;
        font-size: 15px;
        font-weight: 500;
        transition: all 0.2s ease;
        border-radius: 8px;
        margin: 0 12px 0 0;
    }
    .topnav a:hover {
        background-color: #f3f4f6;
        color: #1f2937;
    }
    .blog-meta {
        margin: 32px 0;
        padding: 20px 0;
        border-bottom: 1px solid #e5e7eb;
        display: flex;
        justify-content: space-between;
        align-items: center;
        flex-wrap: wrap;
        gap: 16px;
    }
    .blog-meta p {
        margin: 0;
        color: #6b7280;
        font-size: 14px;
    }
    .follow-buttons {
        display: flex;
        gap: 12px;
    }
    .follow-btn {
        display: inline-flex;
        align-items: center;
        gap: 6px;
        padding: 6px 12px;
        border-radius: 6px;
        text-decoration: none;
        font-size: 13px;
        font-weight: 500;
        transition: all 0.2s ease;
        border: 1px solid #e5e7eb;
        background: #ffffff;
        color: #374151;
    }
    .follow-btn:hover {
        background: #f9fafb;
        border-color: #d1d5db;
        transform: translateY(-1px);
    }
    .btn-icon {
        width: 16px;
        height: 16px;
    }
    h1 {
        color: #111827 !important;
        font-size: 2.25rem !important;
        font-weight: 700 !important;
        line-height: 1.2 !important;
        margin: 24px 0 16px 0 !important;
    }
    h2 {
        color: #1f2937 !important;
        font-size: 1.5rem !important;
        font-weight: 600 !important;
        margin: 32px 0 16px 0 !important;
        line-height: 1.3 !important;
    }
    h3 {
        color: #1f2937 !important;
        font-size: 1.25rem !important;
        font-weight: 600 !important;
        margin: 24px 0 12px 0 !important;
        line-height: 1.3 !important;
    }
    p {
        margin: 16px 0;
        color: #374151;
    }
    ul, ol {
        margin: 16px 0;
        color: #374151;
    }
    li {
        margin: 8px 0;
    }
    .prose {
        max-width: none;
    }
    a {
        color: #2563eb;
        text-decoration: none;
    }
    a:hover {
        color: #1d4ed8;
        text-decoration: underline;
    }
    code {
        background-color: #f8fafc;
        padding: 0.2em 0.4em;
        border-radius: 3px;
        font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
        font-size: 0.9em;
    }
    blockquote {
        border-left: 4px solid #2563eb;
        margin: 1.5em 0;
        padding: 0.5em 1em;
        background-color: #f3f4f6;
        color: #6b7280;
    }
    img {
        width: 80%;
        max-width: 500px;
        height: auto;
        border-radius: 6px;
        margin: 1.5em auto;
        display: block;
    }
    @media (max-width: 768px) {
        body { margin-top: 70px; }
        .topnav { height: 60px; padding: 0 16px; }
        .topnav a { padding: 8px 12px; font-size: 14px; margin-right: 8px; }
        .blog-meta { flex-direction: column; align-items: flex-start; }
        h1 { font-size: 1.875rem !important; }
    }
</style>
</head>

<body class="bg-white text-black">
<div class="topnav">
<a href="../index.html">Home</a>
<a href="../blog.html">Blog</a>
</div>

<main class="max-w-3xl mx-auto px-4 py-10">
<article class="prose max-w-none">
<h1 class="text-3xl font-bold text-black">Unlocking Capabilities Beyond Pre-training: Fine-Tuning and Other Techniques</h1>

<div class="blog-meta">
    <p>Posted on September 24, 2023 by Jiachen Liu</p>  
     <div class="follow-buttons">
        <a href="https://x.com/JIACHENLIU8" target="_blank" class="follow-btn">
            <svg class="btn-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"/>
            </svg>
            X
        </a>
        <a href="https://www.linkedin.com/in/jiachen-amber-liu-872506169/" target="_blank" class="follow-btn">
            <svg class="btn-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z" fill="currentColor"/>
            </svg>
            LinkedIn
        </a>
    </div>
</div>

<section class="mt-8">
<h2>Introduction</h2>
<p>Machine learning practitioners often encounter large language models that are pre-trained on extensive datasets to predict the next token in a sequence. While these models are powerful, they aren't necessarily optimized for specific tasks or to answer particular questions. That's where fine-tuning comes into play.</p>

<p>During an internal tutorial session on fine-tuning large language models, I realized that there are several essential concepts and techniques worth discussing in-depth. This blog post aims to shed light on multiple ways to enhance your language model's performance, in addition to fine-tuning, and help you make an informed decision about which technique to use for your specific needs.</p>
</section>

<section class="mt-10">
<h2>Prompt Engineering</h2>
<p>Prompt Engineering involves carefully crafting the instruction (or 'prompt') given to a language model in order to elicit a specific type of response. By making the prompt more concise, more professional, or geared towards a certain task, we can significantly influence the output of the model.</p>

<h3>Example:</h3>
<ul class="list-disc pl-6">
  <li>Non-engineered Prompt: <code>Tell me about climate change.</code></li>
  <li>Engineered Prompt: <code>Provide a comprehensive, academic-style overview of climate change, focusing on its causes and effects.</code></li>
</ul>

<h3>Advantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Resource Efficiency</strong>: Requires no additional computational cost.</li>
  <li><strong>Precise Control</strong>: The prompt allows precise control over what the model generates.</li>
</ul>

<h3>Disadvantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Context Length Limit</strong>: Long instructions may exceed the context limit of the model.</li>
  <li><strong>Increased Latency</strong>: More tokens in the prompt can increase inference time.</li>
  <li><strong>Lack of Depth</strong>: While prompt engineering can steer the model, it does not add any domain-specific depth.</li>
</ul>
</section>

<section class="mt-10">
<h2>Vanilla Fine-Tuning</h2>
<p>Vanilla Fine-Tuning is the process of adapting a pre-trained model to a specific task by further training it on a smaller domain-specific dataset. This method retrains all the model weights and is akin to the original pre-training process, albeit on a more narrow dataset.</p>

<h3>Advantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Improved Performance</strong>: Gains expertise in the target domain. Leads to more accurate and relevant results for the task at hand.</li>
</ul>

<h3>Disadvantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Resource Intensive</strong>: Require the same resources such as GPU memory as in the original pre-training stage.</li>
</ul>
</section>

<section class="mt-10">
<h2>Instruction Tuning</h2>
<p>Instruction Tuning primarily utilizes a dataset composed of pairs of instructions and corresponding responses. This approach aims to bridge the gap between the model's generic next-word prediction objectives and the user's specific intent or instructions.</p>

<h3>Advantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Predictable Behavior</strong>: The model can be conditioned to act in a specific way.</li>
  <li><strong>Versatility</strong>: Enables the model to perform tasks it wasn't explicitly trained for.</li>
</ul>

<h3>Disadvantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Dataset Complexity</strong>: Requires carefully curated instruction-response pairs.</li>
</ul>

<figure class="my-8">
  <img src="figs/instruction.png" alt="Difference among different techniques">
</figure>
<figure class="my-8">
  <img src="figs/compare.png" alt="Instruction Tuning">
</figure>
</section>

<section class="mt-10">
<h2>Retrieval-Augmented Generation (RAG)</h2>
<p>Retrieval-Augmented Generation (RAG) is an innovative approach that combines the prowess of language models with the ability to pull in external knowledge. In a typical RAG setup, a vector database is used to retrieve context-relevant information, which is then organized into the prompt fed to the language model.</p>

<h3>Advantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Enhanced Outputs</strong>: Combines internal model knowledge with external databases for richer context.</li>
  <li><strong>Task Versatility</strong>: Can be adapted for a variety of tasks where external information is beneficial.</li>
</ul>

<h3>Disadvantages:</h3>
<ul class="list-disc pl-6">
  <li><strong>Accuracy of Retrieval</strong>: May not always fetch the most relevant or complete information.</li>
  <li><strong>Context Limitations</strong>: Can misinterpret the context, leading to irrelevant retrievals.</li>
</ul>

<figure class="my-8">
  <img src="figs/rag.png" alt="RAG">
</figure>
</section>

<section class="mt-10">
<h2>Parameter-Efficient Fine-Tuning (PEFT)</h2>
<p>Parameter-Efficient Fine-Tuning, often abbreviated as PEFT, is a resource-saving alternative to traditional fine-tuning methods. Unlike Vanilla Fine-Tuning, which updates all the model weights, PEFT focuses only on a subset of model weights.</p>

<h3>Key Features:</h3>
<ul class="list-disc pl-6">
  <li><strong>Resource Efficiency</strong>: Lowers the computational and memory overhead.</li>
  <li><strong>Time-Saving</strong>: Faster fine-tuning cycles.</li>
</ul>

<figure class="my-8">
  <img src="figs/peft.png" alt="PEFT">
</figure>

<blockquote>
  <strong>Note</strong>: We'll dive deeper into PEFT in an upcoming blog post, so stay tuned!
</blockquote>
</section>

<section class="mt-10">
<h2>Reinforcement Learning from Human Feedback (RLHF)</h2>
<p>Reinforcement Learning from Human Feedback (RLHF) is a promising but still emerging technique to align large language models more closely with human preferences. The primary goal of RLHF is to incorporate more nuanced behaviors like emotional awareness into the model's responses.</p>

<h3>Challenges:</h3>
<ul class="list-disc pl-6">
  <li><strong>Unstable Performance</strong>: Currently reported to offer inconsistent results.</li>
  <li><strong>Complex Training</strong>: Requires highly specialized training setups.</li>
</ul>

<blockquote>
  <strong>Note</strong>: Due to its research-oriented nature and current limitations, we won't delve deep into RLHF in this post. However, it remains an exciting field for future exploration.
</blockquote>
</section>

<section class="mt-10">
<h2>Sources</h2>
<ol class="list-decimal pl-6">
  <li>Challenges and Applications of Large Language Models</li>
  <li>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</li>
  <li><a href="https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2" target="_blank">Microsoft Build Session</a></li>
  <li><a href="https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf" target="_blank">Stanford CS224n Lecture</a></li>
  <li><a href="http://www-personal.umich.edu/~amberljc/file/llm-fine-tuning.pdf" target="_blank">LLM Fine-tuning Guide</a></li>
</ol>
</section>

</article>
</main>

<footer class="border-t border-blue-200 py-6">
<div class="max-w-4xl mx-auto px-4 text-sm text-gray-600">© AmberLJC</div>
</footer>

</body>
</html>